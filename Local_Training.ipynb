{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mouse Facial Expressions - 로컬 학습\n",
    "\n",
    "이 노트북은 로컬 Anaconda 환경에서 모델을 학습하기 위한 것입니다.\n",
    "\n",
    "## 시작하기 전에:\n",
    "1. Anaconda가 설치되어 있어야 합니다\n",
    "2. 터미널에서 실행: `jupyter notebook`\n",
    "3. 이 노트북을 열고 실행\n",
    "\n",
    "## 예상 시간:\n",
    "- CPU: 7-8시간 (밤새 실행 추천)\n",
    "- 각 epoch: 약 40-50분"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: 환경 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 디렉토리: /Users/minakang/Desktop/mouse-facial-expressions-2023-main\n",
      "Python 버전: 3.13.5 | packaged by Anaconda, Inc. | (main, Jun 12 2025, 11:23:37) [Clang 14.0.6 ]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# 프로젝트 디렉토리로 이동\n",
    "project_dir = '/Users/minakang/Desktop/mouse-facial-expressions-2023-main'\n",
    "os.chdir(project_dir)\n",
    "\n",
    "print(f\"현재 디렉토리: {os.getcwd()}\")\n",
    "print(f\"Python 버전: {sys.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch 버전: 2.9.1\n",
      "Lightning 버전: 2.5.6\n",
      "MLflow 버전: 3.6.0\n",
      "\n",
      "CUDA available: False\n",
      "MPS available: True\n",
      "\n",
      "⚠️ 이 노트북은 CPU로 학습합니다 (안정성을 위해)\n"
     ]
    }
   ],
   "source": [
    "# 필요한 패키지 확인\n",
    "import torch\n",
    "import lightning\n",
    "import mlflow\n",
    "\n",
    "print(f\"PyTorch 버전: {torch.__version__}\")\n",
    "print(f\"Lightning 버전: {lightning.__version__}\")\n",
    "print(f\"MLflow 버전: {mlflow.__version__}\")\n",
    "\n",
    "# CPU/GPU 확인\n",
    "print(f\"\\nCUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"MPS available: {torch.backends.mps.is_available()}\")\n",
    "print(\"\\n⚠️ 이 노트북은 CPU로 학습합니다 (안정성을 위해)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 0\n",
      "drwx------  199 minakang  staff   6.2K Nov 23 15:37 \u001b[34mf1_rec0_acclimation\u001b[m\u001b[m\n",
      "drwx------  195 minakang  staff   6.1K Nov 23 15:37 \u001b[34mf1_rec1_preinjection\u001b[m\u001b[m\n",
      "drwx------  197 minakang  staff   6.2K Nov 23 15:40 \u001b[34mf1_rec2_1h-postinjection\u001b[m\u001b[m\n",
      "drwx------  194 minakang  staff   6.1K Nov 23 15:41 \u001b[34mf1_rec3_2h-postinjection\u001b[m\u001b[m\n",
      "drwx------  201 minakang  staff   6.3K Nov 23 15:39 \u001b[34mf1_rec4_4h-postinjection\u001b[m\u001b[m\n",
      "drwx------  193 minakang  staff   6.0K Nov 23 15:37 \u001b[34mf10_rec0_acclimation\u001b[m\u001b[m\n",
      "drwx------  190 minakang  staff   5.9K Nov 23 15:36 \u001b[34mf10_rec1_preinjection\u001b[m\u001b[m\n",
      "drwx------  199 minakang  staff   6.2K Nov 23 15:36 \u001b[34mf10_rec2_1h-postinjection\u001b[m\u001b[m\n",
      "drwx------  201 minakang  staff   6.3K Nov 23 15:35 \u001b[34mf10_rec3_2h-postinjection\u001b[m\u001b[m\n",
      "drwx------  201 minakang  staff   6.3K Nov 23 15:34 \u001b[34mf10_rec4_4h-postinjection\u001b[m\u001b[m\n",
      "drwx------  203 minakang  staff   6.3K Nov 23 15:31 \u001b[34mf11_rec0_acclimation\u001b[m\u001b[m\n",
      "drwx------  200 minakang  staff   6.3K Nov 23 15:34 \u001b[34mf11_rec1_preinjection\u001b[m\u001b[m\n",
      "drwx------  202 minakang  staff   6.3K Nov 23 15:34 \u001b[34mf11_rec2_1h-postinjection\u001b[m\u001b[m\n",
      "drwx------  195 minakang  staff   6.1K Nov 23 15:37 \u001b[34mf11_rec3_2h-postinjection\u001b[m\u001b[m\n",
      "drwx------  202 minakang  staff   6.3K Nov 23 15:33 \u001b[34mf11_rec4_4h-postinjection\u001b[m\u001b[m\n",
      "drwx------  201 minakang  staff   6.3K Nov 23 15:32 \u001b[34mf12_rec0_acclimation\u001b[m\u001b[m\n",
      "drwx------  199 minakang  staff   6.2K Nov 23 15:33 \u001b[34mf12_rec1_preinjection\u001b[m\u001b[m\n",
      "drwx------  201 minakang  staff   6.3K Nov 23 15:35 \u001b[34mf12_rec2_1h-postinjection\u001b[m\u001b[m\n",
      "drwx------  203 minakang  staff   6.3K Nov 23 15:32 \u001b[34mf12_rec3_2h-postinjection\u001b[m\u001b[m\n",
      "ls: stdout: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "# 로컬 프레임 확인\n",
    "!ls -lh data/local_frames/ | head -20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 12200\n",
      "-rw-------  1 minakang  staff   1.5M Nov 23 09:19 dataset_df.pkl\n",
      "-rw-------  1 minakang  staff   168K Nov 23 09:20 eval.pkl\n",
      "-rw-------  1 minakang  staff   538K Nov 23 09:19 fold0.pkl\n",
      "-rw-------  1 minakang  staff   538K Nov 23 09:19 fold1.pkl\n",
      "-rw-------  1 minakang  staff   538K Nov 23 09:19 fold2.pkl\n",
      "-rw-------  1 minakang  staff   538K Nov 23 09:19 fold3.pkl\n",
      "-rw-------  1 minakang  staff   538K Nov 23 09:20 fold4.pkl\n",
      "-rw-------  1 minakang  staff   538K Nov 23 09:20 fold5.pkl\n",
      "-rw-------  1 minakang  staff   538K Nov 23 09:20 fold6.pkl\n",
      "-rw-------  1 minakang  staff   538K Nov 23 09:20 fold7.pkl\n",
      "-rw-------  1 minakang  staff   395B Nov 23 09:19 README.txt\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 확인\n",
    "!ls -lh data/processed/task-1.1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   32771\n"
     ]
    }
   ],
   "source": [
    "# 프레임 개수 확인\n",
    "!find data/local_frames -name \"*.png\" | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: 환경 변수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ .env 업데이트 완료!\n"
     ]
    }
   ],
   "source": [
    "env_content = \"\"\"MFE_RAW_VIDEO_FOLDER=/Users/minakang/Desktop/mouse-facial-expressions-2023-main/data/raw\n",
    "MFE_RAW_CSV_FOLDER=/Users/minakang/Desktop/mouse-facial-expressions-2023-main/data/raw\n",
    "MFE_VERSION=20230627\n",
    "MFE_PROCESSED_VIDEO_FOLDER=/Users/minakang/Desktop/mouse-facial-expressions-2023-main/data/processed\n",
    "MFE_EXTRACTED_FRAMES_FOLDER=/Users/minakang/Desktop/mouse-facial-expressions-2023-main/data/frames_backup\n",
    "MFE_TASKS=/Users/minakang/Desktop/mouse-facial-expressions-2023-main/data/processed\n",
    "\"\"\"\n",
    "\n",
    "with open('.env', 'w') as f:\n",
    "    f.write(env_content)\n",
    "print(\"✅ .env 업데이트 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFE_RAW_VIDEO_FOLDER=/Users/minakang/Desktop/mouse-facial-expressions-2023-main/data/raw\n",
      "MFE_RAW_CSV_FOLDER=/Users/minakang/Desktop/mouse-facial-expressions-2023-main/data/raw\n",
      "MFE_VERSION=20230627\n",
      "MFE_PROCESSED_VIDEO_FOLDER=/Users/minakang/Desktop/mouse-facial-expressions-2023-main/data/processed\n",
      "MFE_EXTRACTED_FRAMES_FOLDER=/Users/minakang/Desktop/mouse-facial-expressions-2023-main/data/local_frames\n",
      "MFE_TASKS=/Users/minakang/Desktop/mouse-facial-expressions-2023-main/data/processed\n"
     ]
    }
   ],
   "source": [
    "# .env 파일 확인\n",
    "!cat .env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-23 15:57:42,908 - __main__ - INFO - \n",
      "Task1 classification task using sets of 1 frames\n",
      "\n",
      "Classes:\n",
      "- 0: All animals at preinjection\n",
      "- 1: LPS High dose at 4 hours\n",
      "\n",
      "To balance the training datset (n=10000), classes are first sampled\n",
      "randomly then videos are randomly sampled and finally frames.\n",
      "\n",
      "The testing dataset (n=1000) only samples by video, preserving imbalances\n",
      "in the dataset.\n",
      "\n",
      "Split over 8 stratified kfolds grouped by mouse.\n",
      "\n",
      "2025-11-23 15:57:42,908 - __main__ - INFO - Seeding 13641\n",
      "2025-11-23 15:57:42,908 - __main__ - INFO - Loading treatment csv\n",
      "Listing directories in /Users/minakang/Desktop/mouse-facial-expressions-2023-main/data/frames_backup...\n",
      "Traceback (most recent call last):\n",
      "  File \u001b[35m\"/Users/minakang/Desktop/mouse-facial-expressions-2023-main/mouse_facial_expressions/data/make_datasets.py\"\u001b[0m, line \u001b[35m406\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    \u001b[31mmain\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "    \u001b[31m~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/anaconda3/lib/python3.13/site-packages/click/core.py\"\u001b[0m, line \u001b[35m1161\u001b[0m, in \u001b[35m__call__\u001b[0m\n",
      "    return \u001b[31mself.main\u001b[0m\u001b[1;31m(*args, **kwargs)\u001b[0m\n",
      "           \u001b[31m~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/anaconda3/lib/python3.13/site-packages/click/core.py\"\u001b[0m, line \u001b[35m1082\u001b[0m, in \u001b[35mmain\u001b[0m\n",
      "    rv = self.invoke(ctx)\n",
      "  File \u001b[35m\"/opt/anaconda3/lib/python3.13/site-packages/click/core.py\"\u001b[0m, line \u001b[35m1697\u001b[0m, in \u001b[35minvoke\u001b[0m\n",
      "    return _process_result(\u001b[31msub_ctx.command.invoke\u001b[0m\u001b[1;31m(sub_ctx)\u001b[0m)\n",
      "                           \u001b[31m~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/anaconda3/lib/python3.13/site-packages/click/core.py\"\u001b[0m, line \u001b[35m1443\u001b[0m, in \u001b[35minvoke\u001b[0m\n",
      "    return \u001b[31mctx.invoke\u001b[0m\u001b[1;31m(self.callback, **ctx.params)\u001b[0m\n",
      "           \u001b[31m~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/anaconda3/lib/python3.13/site-packages/click/core.py\"\u001b[0m, line \u001b[35m788\u001b[0m, in \u001b[35minvoke\u001b[0m\n",
      "    return __callback(*args, **kwargs)\n",
      "  File \u001b[35m\"/Users/minakang/Desktop/mouse-facial-expressions-2023-main/mouse_facial_expressions/data/make_datasets.py\"\u001b[0m, line \u001b[35m103\u001b[0m, in \u001b[35mtask1\u001b[0m\n",
      "    combined_df = get_treatment_video_dataframe()\n",
      "  File \u001b[35m\"/Users/minakang/Desktop/mouse-facial-expressions-2023-main/mouse_facial_expressions/data/make_datasets.py\"\u001b[0m, line \u001b[35m33\u001b[0m, in \u001b[35mget_treatment_video_dataframe\u001b[0m\n",
      "    dirs = [d for d in \u001b[31mframes_dir.iterdir\u001b[0m\u001b[1;31m()\u001b[0m if d.is_dir()]\n",
      "                       \u001b[31m~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/anaconda3/lib/python3.13/pathlib/_local.py\"\u001b[0m, line \u001b[35m575\u001b[0m, in \u001b[35miterdir\u001b[0m\n",
      "    with \u001b[31mos.scandir\u001b[0m\u001b[1;31m(root_dir)\u001b[0m as scandir_it:\n",
      "         \u001b[31m~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^\u001b[0m\n",
      "\u001b[1;35mFileNotFoundError\u001b[0m: \u001b[35m[Errno 2] No such file or directory: '/Users/minakang/Desktop/mouse-facial-expressions-2023-main/data/frames_backup'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python mouse_facial_expressions/data/make_datasets.py task1 --version \"1.1\" --frameset_size 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: 학습 시작\n",
    "\n",
    "### Option A: 전체 학습 (10 epochs, 7-8시간)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-23 15:56:29,614 - __main__ - INFO - beginning model run train_task1_baseline_model.py\n",
      "/opt/anaconda3/lib/python3.13/site-packages/mlflow/tracking/_tracking_service/utils.py:140: FutureWarning: Filesystem tracking backend (e.g., './mlruns') is deprecated. Please switch to a database backend (e.g., 'sqlite:///mlflow.db'). For feedback, see: https://github.com/mlflow/mlflow/issues/18534\n",
      "  return FileStore(store_uri, store_uri)\n",
      "2025/11/23 15:56:30 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Cmd('git') failed due to: exit code(1)\n",
      "  cmdline: git version\n",
      "  stderr: 'xcode-select: note: No developer tools were found, requesting install.\n",
      "If developer tools are located at a non-default location on disk, use `sudo xcode-select --switch path/to/Xcode.app` to specify the Xcode that you wish to use for command line developer tools, and cancel the installation dialog.\n",
      "See `man xcode-select` for more details.'\n",
      "2025-11-23 15:56:30,017 - __main__ - INFO - Started mlflow crossvalidation run 696c2b7cb89340a4b98f6b0f1f02d86e\n",
      "2025-11-23 15:56:30,017 - __main__ - INFO - Logging parameters\n",
      "{\n",
      "    \"epochs\": 10,\n",
      "    \"dataset_version\": \"1.1\",\n",
      "    \"model\": 10,\n",
      "    \"learning_rate\": 0.01,\n",
      "    \"train_batch_size\": 20,\n",
      "    \"test_batch_size\": 50,\n",
      "    \"warmup_steps\": 0,\n",
      "    \"momentum\": 0.9,\n",
      "    \"weight_decay\": 0.0001,\n",
      "    \"warmup_decay\": 0.0001,\n",
      "    \"label_smoothing\": 0.1,\n",
      "    \"train_augmentation\": \"TrivialAugmentWide\",\n",
      "    \"seed\": 97531\n",
      "}\n",
      "2025-11-23 15:56:30,055 - __main__ - INFO - Starting training for fold 0 with seed 97531\n",
      "2025-11-23 15:56:30,055 - __main__ - INFO - Logging parameters\n",
      "{\n",
      "    \"epochs\": 10,\n",
      "    \"dataset_version\": \"1.1\",\n",
      "    \"model\": 10,\n",
      "    \"learning_rate\": 0.01,\n",
      "    \"train_batch_size\": 20,\n",
      "    \"test_batch_size\": 50,\n",
      "    \"warmup_steps\": 0,\n",
      "    \"momentum\": 0.9,\n",
      "    \"weight_decay\": 0.0001,\n",
      "    \"warmup_decay\": 0.0001,\n",
      "    \"label_smoothing\": 0.1,\n",
      "    \"train_augmentation\": \"TrivialAugmentWide\",\n",
      "    \"seed\": 97531\n",
      "}\n",
      "2025-11-23 15:56:30,094 - __main__ - INFO - Creating dataloader\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "/opt/anaconda3/lib/python3.13/site-packages/lightning/pytorch/trainer/setup.py:166: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "\n",
      "  | Name      | Type               | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | model_    | ResNet             | 21.3 M | train\n",
      "1 | fc        | Linear             | 4      | train\n",
      "2 | criterion | CrossEntropyLoss   | 0      | train\n",
      "3 | train_acc | MulticlassAccuracy | 0      | train\n",
      "4 | val_acc   | MulticlassAccuracy | 0      | train\n",
      "---------------------------------------------------------\n",
      "21.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "21.3 M    Total params\n",
      "85.141    Total estimated model params size (MB)\n",
      "120       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/lib/python3.13/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:428: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n",
      "Traceback (most recent call last):\n",
      "  File \u001b[35m\"/Users/minakang/Desktop/mouse-facial-expressions-2023-main/mouse_facial_expressions/models/train_task1_baseline_model.py\"\u001b[0m, line \u001b[35m236\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    \u001b[31mmain\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "    \u001b[31m~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/anaconda3/lib/python3.13/site-packages/click/core.py\"\u001b[0m, line \u001b[35m1161\u001b[0m, in \u001b[35m__call__\u001b[0m\n",
      "    return \u001b[31mself.main\u001b[0m\u001b[1;31m(*args, **kwargs)\u001b[0m\n",
      "           \u001b[31m~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/anaconda3/lib/python3.13/site-packages/click/core.py\"\u001b[0m, line \u001b[35m1082\u001b[0m, in \u001b[35mmain\u001b[0m\n",
      "    rv = self.invoke(ctx)\n",
      "  File \u001b[35m\"/opt/anaconda3/lib/python3.13/site-packages/click/core.py\"\u001b[0m, line \u001b[35m1443\u001b[0m, in \u001b[35minvoke\u001b[0m\n",
      "    return \u001b[31mctx.invoke\u001b[0m\u001b[1;31m(self.callback, **ctx.params)\u001b[0m\n",
      "           \u001b[31m~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/anaconda3/lib/python3.13/site-packages/click/core.py\"\u001b[0m, line \u001b[35m788\u001b[0m, in \u001b[35minvoke\u001b[0m\n",
      "    return __callback(*args, **kwargs)\n",
      "  File \u001b[35m\"/Users/minakang/Desktop/mouse-facial-expressions-2023-main/mouse_facial_expressions/models/train_task1_baseline_model.py\"\u001b[0m, line \u001b[35m201\u001b[0m, in \u001b[35mmain\u001b[0m\n",
      "    \u001b[31mtrainer.fit\u001b[0m\u001b[1;31m(model, train_dataloader, test_dataloader)\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/anaconda3/lib/python3.13/site-packages/lightning/pytorch/trainer/trainer.py\"\u001b[0m, line \u001b[35m560\u001b[0m, in \u001b[35mfit\u001b[0m\n",
      "    \u001b[31mcall._call_and_handle_interrupt\u001b[0m\u001b[1;31m(\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^\u001b[0m\n",
      "        \u001b[1;31mself, self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "    \u001b[1;31m)\u001b[0m\n",
      "    \u001b[1;31m^\u001b[0m\n",
      "  File \u001b[35m\"/opt/anaconda3/lib/python3.13/site-packages/lightning/pytorch/trainer/call.py\"\u001b[0m, line \u001b[35m49\u001b[0m, in \u001b[35m_call_and_handle_interrupt\u001b[0m\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "  File \u001b[35m\"/opt/anaconda3/lib/python3.13/site-packages/lightning/pytorch/trainer/trainer.py\"\u001b[0m, line \u001b[35m598\u001b[0m, in \u001b[35m_fit_impl\u001b[0m\n",
      "    \u001b[31mself._run\u001b[0m\u001b[1;31m(model, ckpt_path=ckpt_path)\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/anaconda3/lib/python3.13/site-packages/lightning/pytorch/trainer/trainer.py\"\u001b[0m, line \u001b[35m1011\u001b[0m, in \u001b[35m_run\u001b[0m\n",
      "    results = self._run_stage()\n",
      "  File \u001b[35m\"/opt/anaconda3/lib/python3.13/site-packages/lightning/pytorch/trainer/trainer.py\"\u001b[0m, line \u001b[35m1053\u001b[0m, in \u001b[35m_run_stage\u001b[0m\n",
      "    \u001b[31mself._run_sanity_check\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/anaconda3/lib/python3.13/site-packages/lightning/pytorch/trainer/trainer.py\"\u001b[0m, line \u001b[35m1082\u001b[0m, in \u001b[35m_run_sanity_check\u001b[0m\n",
      "    \u001b[31mval_loop.run\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/anaconda3/lib/python3.13/site-packages/lightning/pytorch/loops/utilities.py\"\u001b[0m, line \u001b[35m179\u001b[0m, in \u001b[35m_decorator\u001b[0m\n",
      "    return loop_run(self, *args, **kwargs)\n",
      "  File \u001b[35m\"/opt/anaconda3/lib/python3.13/site-packages/lightning/pytorch/loops/evaluation_loop.py\"\u001b[0m, line \u001b[35m138\u001b[0m, in \u001b[35mrun\u001b[0m\n",
      "    batch, batch_idx, dataloader_idx = \u001b[31mnext\u001b[0m\u001b[1;31m(data_fetcher)\u001b[0m\n",
      "                                       \u001b[31m~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/anaconda3/lib/python3.13/site-packages/lightning/pytorch/loops/fetchers.py\"\u001b[0m, line \u001b[35m134\u001b[0m, in \u001b[35m__next__\u001b[0m\n",
      "    batch = super().__next__()\n",
      "  File \u001b[35m\"/opt/anaconda3/lib/python3.13/site-packages/lightning/pytorch/loops/fetchers.py\"\u001b[0m, line \u001b[35m61\u001b[0m, in \u001b[35m__next__\u001b[0m\n",
      "    batch = next(self.iterator)\n",
      "  File \u001b[35m\"/opt/anaconda3/lib/python3.13/site-packages/lightning/pytorch/utilities/combined_loader.py\"\u001b[0m, line \u001b[35m341\u001b[0m, in \u001b[35m__next__\u001b[0m\n",
      "    out = next(self._iterator)\n",
      "  File \u001b[35m\"/opt/anaconda3/lib/python3.13/site-packages/lightning/pytorch/utilities/combined_loader.py\"\u001b[0m, line \u001b[35m142\u001b[0m, in \u001b[35m__next__\u001b[0m\n",
      "    out = next(self.iterators[0])\n",
      "  File \u001b[35m\"/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py\"\u001b[0m, line \u001b[35m732\u001b[0m, in \u001b[35m__next__\u001b[0m\n",
      "    data = self._next_data()\n",
      "  File \u001b[35m\"/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py\"\u001b[0m, line \u001b[35m1506\u001b[0m, in \u001b[35m_next_data\u001b[0m\n",
      "    return \u001b[31mself._process_data\u001b[0m\u001b[1;31m(data, worker_id)\u001b[0m\n",
      "           \u001b[31m~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py\"\u001b[0m, line \u001b[35m1541\u001b[0m, in \u001b[35m_process_data\u001b[0m\n",
      "    \u001b[31mdata.reraise\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/anaconda3/lib/python3.13/site-packages/torch/_utils.py\"\u001b[0m, line \u001b[35m769\u001b[0m, in \u001b[35mreraise\u001b[0m\n",
      "    raise exception\n",
      "\u001b[1;35mFileNotFoundError\u001b[0m: \u001b[35mCaught FileNotFoundError in DataLoader worker process 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n",
      "    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "            ~~~~~~~~~~~~^^^^^\n",
      "  File \"/Users/minakang/Desktop/mouse-facial-expressions-2023-main/mouse_facial_expressions/data/datasets.py\", line 72, in __getitem__\n",
      "    images = torch.stack(self.df.loc[indices].image.apply(self.get_image).tolist())\n",
      "                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/pandas/core/series.py\", line 4924, in apply\n",
      "    ).apply()\n",
      "      ~~~~~^^\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/pandas/core/apply.py\", line 1427, in apply\n",
      "    return self.apply_standard()\n",
      "           ~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/pandas/core/apply.py\", line 1507, in apply_standard\n",
      "    mapped = obj._map_values(\n",
      "        mapper=curried, na_action=action, convert=self.convert_dtype\n",
      "    )\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/pandas/core/base.py\", line 921, in _map_values\n",
      "    return algorithms.map_array(arr, mapper, na_action=na_action, convert=convert)\n",
      "           ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/pandas/core/algorithms.py\", line 1743, in map_array\n",
      "    return lib.map_infer(values, mapper, convert=convert)\n",
      "           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"lib.pyx\", line 2972, in pandas._libs.lib.map_infer\n",
      "  File \"/Users/minakang/Desktop/mouse-facial-expressions-2023-main/mouse_facial_expressions/data/datasets.py\", line 66, in get_image\n",
      "    return self.transform(imread(self.frame_dir / imagepath))\n",
      "                          ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/skimage/_shared/utils.py\", line 328, in fixed_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/skimage/io/_io.py\", line 82, in imread\n",
      "    img = call_plugin('imread', fname, plugin=plugin, **plugin_args)\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/skimage/_shared/utils.py\", line 538, in wrapped\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/skimage/io/manage_plugins.py\", line 254, in call_plugin\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/skimage/io/_plugins/imageio_plugin.py\", line 11, in imread\n",
      "    out = np.asarray(imageio_imread(*args, **kwargs))\n",
      "                     ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/imageio/v3.py\", line 53, in imread\n",
      "    with imopen(uri, \"r\", **plugin_kwargs) as img_file:\n",
      "         ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/imageio/core/imopen.py\", line 113, in imopen\n",
      "    request = Request(uri, io_mode, format_hint=format_hint, extension=extension)\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/imageio/core/request.py\", line 249, in __init__\n",
      "    self._parse_uri(uri)\n",
      "    ~~~~~~~~~~~~~~~^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/imageio/core/request.py\", line 409, in _parse_uri\n",
      "    raise FileNotFoundError(\"No such file: '%s'\" % fn)\n",
      "FileNotFoundError: No such file: '/Users/minakang/Desktop/mouse-facial-expressions-2023-main/data/local_frames/m3_rec1_preinjection/frame02070.png'\n",
      "\u001b[0m\n",
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# 전체 학습 실행\n",
    "!python mouse_facial_expressions/models/train_task1_baseline_model.py \\\n",
    "    --epochs 10 \\\n",
    "    --dataset_version \"1.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option B: 테스트 실행 (1 epoch, 40-50분)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-23 15:57:01,608 - __main__ - INFO - beginning model run train_task1_baseline_model.py\n",
      "/opt/anaconda3/lib/python3.13/site-packages/mlflow/tracking/_tracking_service/utils.py:140: FutureWarning: Filesystem tracking backend (e.g., './mlruns') is deprecated. Please switch to a database backend (e.g., 'sqlite:///mlflow.db'). For feedback, see: https://github.com/mlflow/mlflow/issues/18534\n",
      "  return FileStore(store_uri, store_uri)\n",
      "2025/11/23 15:57:01 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Cmd('git') failed due to: exit code(1)\n",
      "  cmdline: git version\n",
      "  stderr: 'xcode-select: note: No developer tools were found, requesting install.\n",
      "If developer tools are located at a non-default location on disk, use `sudo xcode-select --switch path/to/Xcode.app` to specify the Xcode that you wish to use for command line developer tools, and cancel the installation dialog.\n",
      "See `man xcode-select` for more details.'\n",
      "2025-11-23 15:57:01,992 - __main__ - INFO - Started mlflow crossvalidation run 2899105732e84594bbb69226c3627ad5\n",
      "2025-11-23 15:57:01,992 - __main__ - INFO - Logging parameters\n",
      "{\n",
      "    \"epochs\": 1,\n",
      "    \"dataset_version\": \"1.1\",\n",
      "    \"model\": 10,\n",
      "    \"learning_rate\": 0.01,\n",
      "    \"train_batch_size\": 20,\n",
      "    \"test_batch_size\": 50,\n",
      "    \"warmup_steps\": 0,\n",
      "    \"momentum\": 0.9,\n",
      "    \"weight_decay\": 0.0001,\n",
      "    \"warmup_decay\": 0.0001,\n",
      "    \"label_smoothing\": 0.1,\n",
      "    \"train_augmentation\": \"TrivialAugmentWide\",\n",
      "    \"seed\": 97531\n",
      "}\n",
      "2025-11-23 15:57:02,028 - __main__ - INFO - Starting training for fold 0 with seed 97531\n",
      "2025-11-23 15:57:02,028 - __main__ - INFO - Logging parameters\n",
      "{\n",
      "    \"epochs\": 1,\n",
      "    \"dataset_version\": \"1.1\",\n",
      "    \"model\": 10,\n",
      "    \"learning_rate\": 0.01,\n",
      "    \"train_batch_size\": 20,\n",
      "    \"test_batch_size\": 50,\n",
      "    \"warmup_steps\": 0,\n",
      "    \"momentum\": 0.9,\n",
      "    \"weight_decay\": 0.0001,\n",
      "    \"warmup_decay\": 0.0001,\n",
      "    \"label_smoothing\": 0.1,\n",
      "    \"train_augmentation\": \"TrivialAugmentWide\",\n",
      "    \"seed\": 97531\n",
      "}\n",
      "2025-11-23 15:57:02,032 - __main__ - INFO - Creating dataloader\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "/opt/anaconda3/lib/python3.13/site-packages/lightning/pytorch/trainer/setup.py:166: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "\n",
      "  | Name      | Type               | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | model_    | ResNet             | 21.3 M | train\n",
      "1 | fc        | Linear             | 4      | train\n",
      "2 | criterion | CrossEntropyLoss   | 0      | train\n",
      "3 | train_acc | MulticlassAccuracy | 0      | train\n",
      "4 | val_acc   | MulticlassAccuracy | 0      | train\n",
      "---------------------------------------------------------\n",
      "21.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "21.3 M    Total params\n",
      "85.141    Total estimated model params size (MB)\n",
      "120       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "Sanity Checking: |                                        | 0/? [00:00<?, ?it/s]/opt/anaconda3/lib/python3.13/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:428: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n",
      "Traceback (most recent call last):\n",
      "  File \u001b[35m\"/Users/minakang/Desktop/mouse-facial-expressions-2023-main/mouse_facial_expressions/models/train_task1_baseline_model.py\"\u001b[0m, line \u001b[35m236\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    \u001b[31mmain\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "    \u001b[31m~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/anaconda3/lib/python3.13/site-packages/click/core.py\"\u001b[0m, line \u001b[35m1161\u001b[0m, in \u001b[35m__call__\u001b[0m\n",
      "    return \u001b[31mself.main\u001b[0m\u001b[1;31m(*args, **kwargs)\u001b[0m\n",
      "           \u001b[31m~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/anaconda3/lib/python3.13/site-packages/click/core.py\"\u001b[0m, line \u001b[35m1082\u001b[0m, in \u001b[35mmain\u001b[0m\n",
      "    rv = self.invoke(ctx)\n",
      "  File \u001b[35m\"/opt/anaconda3/lib/python3.13/site-packages/click/core.py\"\u001b[0m, line \u001b[35m1443\u001b[0m, in \u001b[35minvoke\u001b[0m\n",
      "    return \u001b[31mctx.invoke\u001b[0m\u001b[1;31m(self.callback, **ctx.params)\u001b[0m\n",
      "           \u001b[31m~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/anaconda3/lib/python3.13/site-packages/click/core.py\"\u001b[0m, line \u001b[35m788\u001b[0m, in \u001b[35minvoke\u001b[0m\n",
      "    return __callback(*args, **kwargs)\n",
      "  File \u001b[35m\"/Users/minakang/Desktop/mouse-facial-expressions-2023-main/mouse_facial_expressions/models/train_task1_baseline_model.py\"\u001b[0m, line \u001b[35m201\u001b[0m, in \u001b[35mmain\u001b[0m\n",
      "    \u001b[31mtrainer.fit\u001b[0m\u001b[1;31m(model, train_dataloader, test_dataloader)\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/anaconda3/lib/python3.13/site-packages/lightning/pytorch/trainer/trainer.py\"\u001b[0m, line \u001b[35m560\u001b[0m, in \u001b[35mfit\u001b[0m\n",
      "    \u001b[31mcall._call_and_handle_interrupt\u001b[0m\u001b[1;31m(\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^\u001b[0m\n",
      "        \u001b[1;31mself, self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "    \u001b[1;31m)\u001b[0m\n",
      "    \u001b[1;31m^\u001b[0m\n",
      "  File \u001b[35m\"/opt/anaconda3/lib/python3.13/site-packages/lightning/pytorch/trainer/call.py\"\u001b[0m, line \u001b[35m49\u001b[0m, in \u001b[35m_call_and_handle_interrupt\u001b[0m\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "  File \u001b[35m\"/opt/anaconda3/lib/python3.13/site-packages/lightning/pytorch/trainer/trainer.py\"\u001b[0m, line \u001b[35m598\u001b[0m, in \u001b[35m_fit_impl\u001b[0m\n",
      "    \u001b[31mself._run\u001b[0m\u001b[1;31m(model, ckpt_path=ckpt_path)\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/anaconda3/lib/python3.13/site-packages/lightning/pytorch/trainer/trainer.py\"\u001b[0m, line \u001b[35m1011\u001b[0m, in \u001b[35m_run\u001b[0m\n",
      "    results = self._run_stage()\n",
      "  File \u001b[35m\"/opt/anaconda3/lib/python3.13/site-packages/lightning/pytorch/trainer/trainer.py\"\u001b[0m, line \u001b[35m1053\u001b[0m, in \u001b[35m_run_stage\u001b[0m\n",
      "    \u001b[31mself._run_sanity_check\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/anaconda3/lib/python3.13/site-packages/lightning/pytorch/trainer/trainer.py\"\u001b[0m, line \u001b[35m1082\u001b[0m, in \u001b[35m_run_sanity_check\u001b[0m\n",
      "    \u001b[31mval_loop.run\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/anaconda3/lib/python3.13/site-packages/lightning/pytorch/loops/utilities.py\"\u001b[0m, line \u001b[35m179\u001b[0m, in \u001b[35m_decorator\u001b[0m\n",
      "    return loop_run(self, *args, **kwargs)\n",
      "  File \u001b[35m\"/opt/anaconda3/lib/python3.13/site-packages/lightning/pytorch/loops/evaluation_loop.py\"\u001b[0m, line \u001b[35m138\u001b[0m, in \u001b[35mrun\u001b[0m\n",
      "    batch, batch_idx, dataloader_idx = \u001b[31mnext\u001b[0m\u001b[1;31m(data_fetcher)\u001b[0m\n",
      "                                       \u001b[31m~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/anaconda3/lib/python3.13/site-packages/lightning/pytorch/loops/fetchers.py\"\u001b[0m, line \u001b[35m134\u001b[0m, in \u001b[35m__next__\u001b[0m\n",
      "    batch = super().__next__()\n",
      "  File \u001b[35m\"/opt/anaconda3/lib/python3.13/site-packages/lightning/pytorch/loops/fetchers.py\"\u001b[0m, line \u001b[35m61\u001b[0m, in \u001b[35m__next__\u001b[0m\n",
      "    batch = next(self.iterator)\n",
      "  File \u001b[35m\"/opt/anaconda3/lib/python3.13/site-packages/lightning/pytorch/utilities/combined_loader.py\"\u001b[0m, line \u001b[35m341\u001b[0m, in \u001b[35m__next__\u001b[0m\n",
      "    out = next(self._iterator)\n",
      "  File \u001b[35m\"/opt/anaconda3/lib/python3.13/site-packages/lightning/pytorch/utilities/combined_loader.py\"\u001b[0m, line \u001b[35m142\u001b[0m, in \u001b[35m__next__\u001b[0m\n",
      "    out = next(self.iterators[0])\n",
      "  File \u001b[35m\"/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py\"\u001b[0m, line \u001b[35m732\u001b[0m, in \u001b[35m__next__\u001b[0m\n",
      "    data = self._next_data()\n",
      "  File \u001b[35m\"/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py\"\u001b[0m, line \u001b[35m1506\u001b[0m, in \u001b[35m_next_data\u001b[0m\n",
      "    return \u001b[31mself._process_data\u001b[0m\u001b[1;31m(data, worker_id)\u001b[0m\n",
      "           \u001b[31m~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py\"\u001b[0m, line \u001b[35m1541\u001b[0m, in \u001b[35m_process_data\u001b[0m\n",
      "    \u001b[31mdata.reraise\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/anaconda3/lib/python3.13/site-packages/torch/_utils.py\"\u001b[0m, line \u001b[35m769\u001b[0m, in \u001b[35mreraise\u001b[0m\n",
      "    raise exception\n",
      "\u001b[1;35mFileNotFoundError\u001b[0m: \u001b[35mCaught FileNotFoundError in DataLoader worker process 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n",
      "    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "            ~~~~~~~~~~~~^^^^^\n",
      "  File \"/Users/minakang/Desktop/mouse-facial-expressions-2023-main/mouse_facial_expressions/data/datasets.py\", line 72, in __getitem__\n",
      "    images = torch.stack(self.df.loc[indices].image.apply(self.get_image).tolist())\n",
      "                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/pandas/core/series.py\", line 4924, in apply\n",
      "    ).apply()\n",
      "      ~~~~~^^\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/pandas/core/apply.py\", line 1427, in apply\n",
      "    return self.apply_standard()\n",
      "           ~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/pandas/core/apply.py\", line 1507, in apply_standard\n",
      "    mapped = obj._map_values(\n",
      "        mapper=curried, na_action=action, convert=self.convert_dtype\n",
      "    )\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/pandas/core/base.py\", line 921, in _map_values\n",
      "    return algorithms.map_array(arr, mapper, na_action=na_action, convert=convert)\n",
      "           ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/pandas/core/algorithms.py\", line 1743, in map_array\n",
      "    return lib.map_infer(values, mapper, convert=convert)\n",
      "           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"lib.pyx\", line 2972, in pandas._libs.lib.map_infer\n",
      "  File \"/Users/minakang/Desktop/mouse-facial-expressions-2023-main/mouse_facial_expressions/data/datasets.py\", line 66, in get_image\n",
      "    return self.transform(imread(self.frame_dir / imagepath))\n",
      "                          ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/skimage/_shared/utils.py\", line 328, in fixed_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/skimage/io/_io.py\", line 82, in imread\n",
      "    img = call_plugin('imread', fname, plugin=plugin, **plugin_args)\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/skimage/_shared/utils.py\", line 538, in wrapped\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/skimage/io/manage_plugins.py\", line 254, in call_plugin\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/skimage/io/_plugins/imageio_plugin.py\", line 11, in imread\n",
      "    out = np.asarray(imageio_imread(*args, **kwargs))\n",
      "                     ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/imageio/v3.py\", line 53, in imread\n",
      "    with imopen(uri, \"r\", **plugin_kwargs) as img_file:\n",
      "         ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/imageio/core/imopen.py\", line 113, in imopen\n",
      "    request = Request(uri, io_mode, format_hint=format_hint, extension=extension)\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/imageio/core/request.py\", line 249, in __init__\n",
      "    self._parse_uri(uri)\n",
      "    ~~~~~~~~~~~~~~~^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/imageio/core/request.py\", line 409, in _parse_uri\n",
      "    raise FileNotFoundError(\"No such file: '%s'\" % fn)\n",
      "FileNotFoundError: No such file: '/Users/minakang/Desktop/mouse-facial-expressions-2023-main/data/local_frames/m3_rec1_preinjection/frame02070.png'\n",
      "\u001b[0m\n",
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# 1 epoch 테스트\n",
    "!python mouse_facial_expressions/models/train_task1_baseline_model.py \\\n",
    "    --epochs 1 \\\n",
    "    --dataset_version \"1.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: 학습 모니터링\n",
    "\n",
    "학습이 진행되는 동안 다른 셀에서 진행 상황을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 0\n"
     ]
    }
   ],
   "source": [
    "# 체크포인트 확인\n",
    "!ls -lht models/checkpoints/ 2>/dev/null || echo \"아직 체크포인트가 없습니다\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프로세스 확인\n",
    "!ps aux | grep train_task1 | grep -v grep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아직 체크포인트가 없습니다\n"
     ]
    }
   ],
   "source": [
    "# 저장된 체크포인트 목록\n",
    "import glob\n",
    "\n",
    "checkpoints = glob.glob('models/checkpoints/*.ckpt')\n",
    "if checkpoints:\n",
    "    print(\"저장된 체크포인트:\")\n",
    "    for ckpt in sorted(checkpoints):\n",
    "        size = os.path.getsize(ckpt) / (1024*1024)  # MB\n",
    "        print(f\"  {os.path.basename(ckpt)} ({size:.1f} MB)\")\n",
    "else:\n",
    "    print(\"아직 체크포인트가 없습니다\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "체크포인트를 찾을 수 없습니다\n"
     ]
    }
   ],
   "source": [
    "# 최고 성능 모델 찾기\n",
    "import re\n",
    "\n",
    "best_acc = 0\n",
    "best_ckpt = None\n",
    "\n",
    "for ckpt in checkpoints:\n",
    "    # 파일명에서 val_acc 추출\n",
    "    match = re.search(r'val_acc=([0-9.]+)', ckpt)\n",
    "    if match:\n",
    "        acc = float(match.group(1))\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_ckpt = ckpt\n",
    "\n",
    "if best_ckpt:\n",
    "    print(f\"\\n최고 성능 모델:\")\n",
    "    print(f\"  파일: {os.path.basename(best_ckpt)}\")\n",
    "    print(f\"  Validation Accuracy: {best_acc:.2%}\")\n",
    "else:\n",
    "    print(\"체크포인트를 찾을 수 없습니다\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: 체크포인트 로드 및 테스트 (선택사항)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체크포인트 로드 예시\n",
    "if best_ckpt:\n",
    "    checkpoint = torch.load(best_ckpt)\n",
    "    print(\"체크포인트 정보:\")\n",
    "    print(f\"  Epoch: {checkpoint.get('epoch', 'N/A')}\")\n",
    "    print(f\"  Keys: {list(checkpoint.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다음 단계: Chronic 데이터로 Fine-tuning\n",
    "\n",
    "학습이 완료되면 `FINE_TUNING_GUIDE.md`를 참고하여 chronic 데이터로 fine-tuning하세요.\n",
    "\n",
    "```python\n",
    "# Fine-tuning 예시\n",
    "!python mouse_facial_expressions/models/finetune_chronic.py \\\n",
    "    --checkpoint_path models/checkpoints/task1-fold0-epoch=9-val_acc=0.95.ckpt \\\n",
    "    --epochs 5 \\\n",
    "    --dataset_version \"chronic_v1\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 유용한 명령어\n",
    "\n",
    "### 백그라운드로 실행하기\n",
    "\n",
    "노트북을 닫아도 학습이 계속되도록 하려면 터미널에서:\n",
    "\n",
    "```bash\n",
    "cd /Users/minakang/Desktop/mouse-facial-expressions-2023-main\n",
    "nohup python mouse_facial_expressions/models/train_task1_baseline_model.py \\\n",
    "    --epochs 10 --dataset_version \"1.1\" > training_log.txt 2>&1 &\n",
    "```\n",
    "\n",
    "### 진행 상황 확인\n",
    "\n",
    "```bash\n",
    "# 로그 확인\n",
    "tail -f training_log.txt\n",
    "\n",
    "# 프로세스 확인\n",
    "ps aux | grep train_task1\n",
    "\n",
    "# 체크포인트 확인\n",
    "ls -lht models/checkpoints/\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
