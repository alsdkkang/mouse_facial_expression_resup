# 전략 분석: 배경 제거(Background Removal) 및 얼굴 분할(Segmentation) 도입

**결론부터 말씀드리면, 현재 상황에서 매우 훌륭하고 효과적인 접근 방식입니다.**

## 1. 왜 이 방식이 필요한가? (Why)
현재 우리가 직면한 가장 큰 문제는 **Cohort 1의 Batch Effect**입니다.
*   **현상**: 모델이 쥐의 표정이 아니라, Cohort 1 영상의 **"어두운 조명"이나 "촬영 각도" 같은 배경 특징**을 "Stress"라고 잘못 학습/판단하고 있습니다.
*   **해결책**: 배경(Background)을 아예 지워버리고 **쥐의 얼굴(Face)만 남기면**, 모델은 강제로 표정에만 집중하게 됩니다. 즉, 조명이나 배경 차이로 인한 오류를 원천 차단할 수 있습니다.

## 2. 적용 방법 (How)

### 방법 A: DLC 좌표 기반 마스킹 (가장 현실적/빠름)
우리는 이미 DeepLabCut(DLC)으로 쥐의 코, 귀, 눈 좌표를 가지고 있습니다.
*   **원리**: DLC 좌표들을 잇는 다각형(Polygon)을 만들거나, 얼굴 중심에서 일정 반경 원(Circle)을 그려서 그 바깥쪽을 검은색(0)으로 칠해버립니다.
*   **장점**: 추가적인 AI 모델 학습이 필요 없고, 계산 속도가 매우 빠릅니다.
*   **단점**: 귀 모양이나 수염 같은 미세한 부분이 잘릴 수 있습니다.

### 방법 B: 정밀 분할 모델 (SAM, U-Net 등)
*   **원리**: Segment Anything Model (SAM) 같은 최신 AI를 써서 쥐의 형상을 정확히 따냅니다.
*   **장점**: 귀, 수염 등을 정확히 살리면서 배경만 완벽히 날릴 수 있습니다.
*   **단점**: 계산 비용이 비싸고(느림), 전처리 시간이 오래 걸립니다.

## 3. 추천 전략 (Recommendation)

**1단계: 현재의 Fine-Tuning 먼저 진행**
*   일단 배경 제거 없이 Fine-Tuning을 돌려봅니다. (현재 준비된 코드)
*   이것만으로도 모델이 "아, 이 어두운 배경이 항상 Stress는 아니구나"라고 학습할 가능성이 높습니다.

**2단계: 성능이 부족하면 '방법 A (DLC 마스킹)' 도입**
*   Fine-Tuning 후에도 여전히 Cohort 1을 못 맞춘다면, 그때 전처리 파이프라인에 **"배경 마스킹"** 기능을 추가합니다.
*   복잡한 SAM보다는, DLC 좌표를 활용한 마스킹이 연구 효율성 면에서 훨씬 좋습니다.

## 4. 예상 효과
이 기술을 적용하면 **"Universal Model" (어떤 환경에서 찍어도 작동하는 모델)**에 훨씬 가까워질 것입니다. 만성 스트레스 모델 구축 시 **강력히 추천하는 옵션**입니다.
