{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mouse Facial Expressions - í•™ìŠµ ë…¸íŠ¸ë¶ (ìˆ˜ì •ë¨)\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ ì²˜ìŒë¶€í„° ë‹¤ì‹œ ì‹œì‘í•˜ì—¬ ëª¨ë“  ê²½ë¡œë¥¼ í™•ì¸í•˜ê³  í•™ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤.\n",
    "\n",
    "## âœ… ìˆ˜ì • ì‚¬í•­\n",
    "- ModelCheckpoint ì—ëŸ¬ ìˆ˜ì •: `val_acc` ë©”íŠ¸ë¦­ì„ Lightningì— ì˜¬ë°”ë¥´ê²Œ ë¡œê¹…í•˜ë„ë¡ ìˆ˜ì •í–ˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: í˜„ì¬ ìƒíƒœ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í˜„ì¬ ë””ë ‰í† ë¦¬: /Users/minakang/Desktop/mouse-facial-expressions-2023-main\n",
      "Python ë²„ì „: 3.13.5 | packaged by Anaconda, Inc. | (main, Jun 12 2025, 11:23:37) [Clang 14.0.6 ]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ë¡œ ì´ë™\n",
    "os.chdir('/Users/minakang/Desktop/mouse-facial-expressions-2023-main')\n",
    "print(f\"í˜„ì¬ ë””ë ‰í† ë¦¬: {os.getcwd()}\")\n",
    "print(f\"Python ë²„ì „: {sys.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch ë²„ì „: 2.9.1\n",
      "Lightning ë²„ì „: 2.5.6\n",
      "MLflow ë²„ì „: 3.6.0\n",
      "\n",
      "CUDA ì‚¬ìš© ê°€ëŠ¥: False\n",
      "MPS ì‚¬ìš© ê°€ëŠ¥: True\n",
      "\n",
      "âš ï¸ ì´ ë…¸íŠ¸ë¶ì€ CPUë¡œ í•™ìŠµí•©ë‹ˆë‹¤ (ì•ˆì •ì„±ì„ ìœ„í•´)\n"
     ]
    }
   ],
   "source": [
    "# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ í™•ì¸\n",
    "import torch\n",
    "import lightning\n",
    "import mlflow\n",
    "\n",
    "print(f\"PyTorch ë²„ì „: {torch.__version__}\")\n",
    "print(f\"Lightning ë²„ì „: {lightning.__version__}\")\n",
    "print(f\"MLflow ë²„ì „: {mlflow.__version__}\")\n",
    "print(f\"\\nCUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}\")\n",
    "print(f\"MPS ì‚¬ìš© ê°€ëŠ¥: {torch.backends.mps.is_available()}\")\n",
    "print(f\"\\nâš ï¸ ì´ ë…¸íŠ¸ë¶ì€ CPUë¡œ í•™ìŠµí•©ë‹ˆë‹¤ (ì•ˆì •ì„±ì„ ìœ„í•´)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 0\n",
      "drwx------    8 minakang  staff   256 Nov 23 16:01 \u001b[34m.\u001b[m\u001b[m\n",
      "drwx------@  48 minakang  staff  1536 Nov 24 08:45 \u001b[34m..\u001b[m\u001b[m\n",
      "drwx------    3 minakang  staff    96 Nov 23 15:30 \u001b[34mdlc\u001b[m\u001b[m\n",
      "drwx------@ 290 minakang  staff  9280 Nov 22 16:28 \u001b[34mframes_backup\u001b[m\u001b[m\n",
      "drwx------    3 minakang  staff    96 Nov 23 15:30 \u001b[34minterim\u001b[m\u001b[m\n",
      "drwx------  289 minakang  staff  9248 Nov 23 15:30 \u001b[34mlocal_frames\u001b[m\u001b[m\n",
      "drwx------    4 minakang  staff   128 Nov 23 15:30 \u001b[34mprocessed\u001b[m\u001b[m\n",
      "drwx------    5 minakang  staff   160 Nov 23 15:31 \u001b[34mraw\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "# ë°ì´í„° í´ë” í™•ì¸\n",
    "!ls -la data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: ë°ì´í„° í™•ì¸\n",
    "\n",
    "í˜„ì¬ ì‚¬ìš© ê°€ëŠ¥í•œ í”„ë ˆì„ ë°ì´í„°ë¥¼ í™•ì¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì‚¬ìš© ê°€ëŠ¥í•œ í”„ë ˆì„ í´ë”:\n",
      "  - data/frames_backup: 57,174 í”„ë ˆì„\n",
      "  - data/local_frames: 57,174 í”„ë ˆì„\n"
     ]
    }
   ],
   "source": [
    "# ì‚¬ìš© ê°€ëŠ¥í•œ í”„ë ˆì„ í´ë” í™•ì¸\n",
    "import os\n",
    "\n",
    "frames_folders = []\n",
    "if os.path.exists('data/frames_backup'):\n",
    "    frames_folders.append('data/frames_backup')\n",
    "if os.path.exists('data/local_frames'):\n",
    "    frames_folders.append('data/local_frames')\n",
    "\n",
    "if frames_folders:\n",
    "    print(\"âœ… ì‚¬ìš© ê°€ëŠ¥í•œ í”„ë ˆì„ í´ë”:\")\n",
    "    for folder in frames_folders:\n",
    "        frame_count = sum(1 for root, dirs, files in os.walk(folder) for f in files if f.endswith('.png'))\n",
    "        print(f\"  - {folder}: {frame_count:,} í”„ë ˆì„\")\n",
    "else:\n",
    "    print(\"âŒ í”„ë ˆì„ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    print(\"\\në‹¤ìŒ ì¤‘ í•˜ë‚˜ë¥¼ ìˆ˜í–‰í•˜ì„¸ìš”:\")\n",
    "    print(\"1. Google Driveì—ì„œ ë°ì´í„°ë¥¼ ë³µì‚¬í•˜ê±°ë‚˜\")\n",
    "    print(\"2. data/local_frames í´ë”ì— í”„ë ˆì„ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: .env íŒŒì¼ ì„¤ì •\n",
    "\n",
    "í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤. í”„ë ˆì„ í´ë” ê²½ë¡œë¥¼ ìë™ìœ¼ë¡œ ê°ì§€í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… frames_backup í´ë”ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤\n",
      "\n",
      "âœ… .env íŒŒì¼ ìƒì„± ì™„ë£Œ!\n",
      "\n",
      "ë‚´ìš©:\n",
      "MFE_RAW_VIDEO_FOLDER=/Users/minakang/Desktop/mouse-facial-expressions-2023-main/data/raw\n",
      "MFE_RAW_CSV_FOLDER=/Users/minakang/Desktop/mouse-facial-expressions-2023-main/data/raw\n",
      "MFE_VERSION=20230627\n",
      "MFE_PROCESSED_VIDEO_FOLDER=/Users/minakang/Desktop/mouse-facial-expressions-2023-main/data/processed\n",
      "MFE_EXTRACTED_FRAMES_FOLDER=/Users/minakang/Desktop/mouse-facial-expressions-2023-main/data/frames_backup\n",
      "MFE_TASKS=/Users/minakang/Desktop/mouse-facial-expressions-2023-main/data/processed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# í”„ë ˆì„ í´ë” ìë™ ê°ì§€\n",
    "import os\n",
    "\n",
    "project_dir = '/Users/minakang/Desktop/mouse-facial-expressions-2023-main'\n",
    "\n",
    "# ìš°ì„ ìˆœìœ„: frames_backup > local_frames\n",
    "if os.path.exists(f'{project_dir}/data/frames_backup'):\n",
    "    frames_folder = f'{project_dir}/data/frames_backup'\n",
    "    print(\"âœ… frames_backup í´ë”ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤\")\n",
    "elif os.path.exists(f'{project_dir}/data/local_frames'):\n",
    "    frames_folder = f'{project_dir}/data/local_frames'\n",
    "    print(\"âœ… local_frames í´ë”ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤\")\n",
    "else:\n",
    "    frames_folder = f'{project_dir}/data/local_frames'\n",
    "    print(\"âš ï¸ í”„ë ˆì„ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. local_framesë¥¼ ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "# .env íŒŒì¼ ìƒì„±\n",
    "env_content = f\"\"\"MFE_RAW_VIDEO_FOLDER={project_dir}/data/raw\n",
    "MFE_RAW_CSV_FOLDER={project_dir}/data/raw\n",
    "MFE_VERSION=20230627\n",
    "MFE_PROCESSED_VIDEO_FOLDER={project_dir}/data/processed\n",
    "MFE_EXTRACTED_FRAMES_FOLDER={frames_folder}\n",
    "MFE_TASKS={project_dir}/data/processed\n",
    "\"\"\"\n",
    "\n",
    "with open('.env', 'w') as f:\n",
    "    f.write(env_content)\n",
    "\n",
    "print(\"\\nâœ… .env íŒŒì¼ ìƒì„± ì™„ë£Œ!\")\n",
    "print(\"\\në‚´ìš©:\")\n",
    "print(env_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: ë°ì´í„°ì…‹ ìƒì„± (í•„ìš”í•œ ê²½ìš°ë§Œ ì‹¤í–‰)\n",
    "\n",
    "âš ï¸ ì´ë¯¸ `data/processed/task-1.1/` ë””ë ‰í† ë¦¬ì— `.pkl` íŒŒì¼ë“¤ì´ ìˆë‹¤ë©´ ì´ ë‹¨ê³„ë¥¼ ê±´ë„ˆë›°ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë°ì´í„°ì…‹ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤ (10ê°œ íŒŒì¼)\n",
      "\n",
      "íŒŒì¼ ëª©ë¡:\n",
      "total 12040\n",
      "-rw-------  1 minakang  staff   1.5M Nov 23 16:01 dataset_df.pkl\n",
      "-rw-------  1 minakang  staff   168K Nov 23 16:02 eval.pkl\n",
      "-rw-------  1 minakang  staff   538K Nov 23 16:01 fold0.pkl\n",
      "-rw-------  1 minakang  staff   538K Nov 23 16:01 fold1.pkl\n",
      "-rw-------  1 minakang  staff   538K Nov 23 16:01 fold2.pkl\n",
      "-rw-------  1 minakang  staff   538K Nov 23 16:01 fold3.pkl\n",
      "-rw-------  1 minakang  staff   538K Nov 23 16:01 fold4.pkl\n",
      "-rw-------  1 minakang  staff   538K Nov 23 16:02 fold5.pkl\n",
      "-rw-------  1 minakang  staff   538K Nov 23 16:02 fold6.pkl\n",
      "-rw-------  1 minakang  staff   538K Nov 23 16:02 fold7.pkl\n",
      "-rw-------@ 1 minakang  staff   395B Nov 23 16:01 README.txt\n"
     ]
    }
   ],
   "source": [
    "# ë°ì´í„°ì…‹ íŒŒì¼ í™•ì¸\n",
    "import os\n",
    "\n",
    "processed_dir = 'data/processed/task-1.1'\n",
    "if os.path.exists(processed_dir):\n",
    "    pkl_files = [f for f in os.listdir(processed_dir) if f.endswith('.pkl')]\n",
    "    if len(pkl_files) > 0:\n",
    "        print(f\"âœ… ë°ì´í„°ì…‹ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤ ({len(pkl_files)}ê°œ íŒŒì¼)\")\n",
    "        print(\"\\níŒŒì¼ ëª©ë¡:\")\n",
    "        !ls -lh data/processed/task-1.1/\n",
    "    else:\n",
    "        print(\"âŒ ë°ì´í„°ì…‹ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ì•„ë˜ ì…€ì„ ì‹¤í–‰í•˜ì—¬ ìƒì„±í•˜ì„¸ìš”.\")\n",
    "else:\n",
    "    print(\"âŒ ë°ì´í„°ì…‹ ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤. ì•„ë˜ ì…€ì„ ì‹¤í–‰í•˜ì—¬ ìƒì„±í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-24 08:47:10,730 - __main__ - INFO - \n",
      "Task1 classification task using sets of 1 frames\n",
      "\n",
      "Classes:\n",
      "- 0: All animals at preinjection\n",
      "- 1: LPS High dose at 4 hours\n",
      "\n",
      "To balance the training datset (n=10000), classes are first sampled\n",
      "randomly then videos are randomly sampled and finally frames.\n",
      "\n",
      "The testing dataset (n=1000) only samples by video, preserving imbalances\n",
      "in the dataset.\n",
      "\n",
      "Split over 8 stratified kfolds grouped by mouse.\n",
      "\n",
      "2025-11-24 08:47:10,730 - __main__ - INFO - Seeding 13641\n",
      "2025-11-24 08:47:10,730 - __main__ - INFO - Loading treatment csv\n",
      "Listing directories in /Users/minakang/Desktop/mouse-facial-expressions-2023-main/data/frames_backup...\n",
      "Found 287 directories. Listing files in parallel...\n",
      "Listing files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 287/287 [00:00<00:00, 1095.45it/s]\n",
      "Found 57174 files.\n",
      "2025-11-24 08:47:11,583 - __main__ - INFO - Removing control mouse (m18) which was identified as having pain/sickness symptoms before experiment start\n",
      "2025-11-24 08:47:11,592 - __main__ - INFO - Assigning labels\n",
      "2025-11-24 08:47:11,609 - __main__ - INFO - Final size of task dataset 9800\n",
      "2025-11-24 08:47:11,611 - __main__ - INFO - Class 0 has 7800 frames\n",
      "2025-11-24 08:47:11,611 - __main__ - INFO - Class 1 has 2000 frames\n",
      "2025-11-24 08:47:11,612 - __main__ - INFO - Saving the dataset\n",
      "2025-11-24 08:47:11,619 - __main__ - INFO - Creating 8 stratified kfold splits, grouped by mouse\n",
      "2025-11-24 08:47:11,637 - __main__ - INFO - \n",
      "Split 0\n",
      " - train mice: m1, m2, m4, m5, m6, m7, m8, m9, m10, m11, m13, m14, m15, m16, m17, m19, m20, f2, f3, f4, f5, f6, f7, f8, f9, f10, f11, f12, f13, f14, f15, f16, f30, f33\n",
      " - test mice: m3, m12, f1, f31, f32\n",
      "2025-11-24 08:47:11,637 - __main__ - INFO - Fetching train samples\n",
      "2025-11-24 08:47:15,247 - __main__ - INFO - Fetching test samples               \n",
      "2025-11-24 08:47:15,413 - __main__ - INFO - Saving samples                      \n",
      "2025-11-24 08:47:15,434 - __main__ - INFO - \n",
      "Split 1\n",
      " - train mice: m1, m2, m3, m4, m5, m7, m8, m9, m10, m11, m12, m14, m15, m16, m17, m19, m20, f1, f2, f3, f4, f5, f6, f7, f9, f10, f12, f13, f14, f15, f16, f30, f31, f32\n",
      " - test mice: m6, m13, f8, f11, f33\n",
      "2025-11-24 08:47:15,434 - __main__ - INFO - Fetching train samples\n",
      "2025-11-24 08:47:19,164 - __main__ - INFO - Fetching test samples               \n",
      "2025-11-24 08:47:19,344 - __main__ - INFO - Saving samples                      \n",
      "2025-11-24 08:47:19,368 - __main__ - INFO - \n",
      "Split 2\n",
      " - train mice: m1, m2, m3, m4, m5, m6, m8, m9, m11, m12, m13, m14, m16, m17, m19, m20, f1, f2, f3, f4, f6, f7, f8, f9, f11, f12, f13, f14, f15, f16, f30, f31, f32, f33\n",
      " - test mice: m7, m10, m15, f5, f10\n",
      "2025-11-24 08:47:19,368 - __main__ - INFO - Fetching train samples\n",
      "2025-11-24 08:47:23,148 - __main__ - INFO - Fetching test samples               \n",
      "2025-11-24 08:47:23,323 - __main__ - INFO - Saving samples                      \n",
      "2025-11-24 08:47:23,348 - __main__ - INFO - \n",
      "Split 3\n",
      " - train mice: m1, m2, m3, m4, m5, m6, m7, m9, m10, m11, m12, m13, m15, m16, m17, m20, f1, f2, f3, f4, f5, f7, f8, f9, f10, f11, f12, f14, f15, f16, f30, f31, f32, f33\n",
      " - test mice: m8, m14, m19, f6, f13\n",
      "2025-11-24 08:47:23,349 - __main__ - INFO - Fetching train samples\n",
      "2025-11-24 08:47:27,177 - __main__ - INFO - Fetching test samples               \n",
      "2025-11-24 08:47:27,347 - __main__ - INFO - Saving samples                      \n",
      "2025-11-24 08:47:27,369 - __main__ - INFO - \n",
      "Split 4\n",
      " - train mice: m1, m2, m3, m5, m6, m7, m8, m9, m10, m12, m13, m14, m15, m16, m17, m19, f1, f2, f3, f4, f5, f6, f8, f9, f10, f11, f12, f13, f15, f16, f30, f31, f32, f33\n",
      " - test mice: m4, m11, m20, f7, f14\n",
      "2025-11-24 08:47:27,369 - __main__ - INFO - Fetching train samples\n",
      "2025-11-24 08:47:31,039 - __main__ - INFO - Fetching test samples               \n",
      "2025-11-24 08:47:31,206 - __main__ - INFO - Saving samples                      \n",
      "2025-11-24 08:47:31,226 - __main__ - INFO - \n",
      "Split 5\n",
      " - train mice: m1, m2, m3, m4, m6, m7, m8, m9, m10, m11, m12, m13, m14, m15, m17, m19, m20, f1, f2, f3, f4, f5, f6, f7, f8, f10, f11, f13, f14, f15, f30, f31, f32, f33\n",
      " - test mice: m5, m16, f9, f12, f16\n",
      "2025-11-24 08:47:31,227 - __main__ - INFO - Fetching train samples\n",
      "2025-11-24 08:47:34,823 - __main__ - INFO - Fetching test samples               \n",
      "2025-11-24 08:47:35,006 - __main__ - INFO - Saving samples                      \n",
      "2025-11-24 08:47:35,030 - __main__ - INFO - \n",
      "Split 6\n",
      " - train mice: m2, m3, m4, m5, m6, m7, m8, m10, m11, m12, m13, m14, m15, m16, m19, m20, f1, f3, f4, f5, f6, f7, f8, f9, f10, f11, f12, f13, f14, f16, f30, f31, f32, f33\n",
      " - test mice: m1, m9, m17, f2, f15\n",
      "2025-11-24 08:47:35,030 - __main__ - INFO - Fetching train samples\n",
      "2025-11-24 08:47:38,759 - __main__ - INFO - Fetching test samples               \n",
      "2025-11-24 08:47:38,941 - __main__ - INFO - Saving samples                      \n",
      "2025-11-24 08:47:38,964 - __main__ - INFO - \n",
      "Split 7\n",
      " - train mice: m1, m3, m4, m5, m6, m7, m8, m9, m10, m11, m12, m13, m14, m15, m16, m17, m19, m20, f1, f2, f5, f6, f7, f8, f9, f10, f11, f12, f13, f14, f15, f16, f31, f32, f33\n",
      " - test mice: m2, f3, f4, f30\n",
      "2025-11-24 08:47:38,964 - __main__ - INFO - Fetching train samples\n",
      "2025-11-24 08:47:42,689 - __main__ - INFO - Fetching test samples               \n",
      "2025-11-24 08:47:42,849 - __main__ - INFO - Saving samples                      \n",
      "2025-11-24 08:47:42,868 - __main__ - INFO - Building evaluation dataset\n",
      "Listing directories in /Users/minakang/Desktop/mouse-facial-expressions-2023-main/data/frames_backup...\n",
      "Found 287 directories. Listing files in parallel...\n",
      "Listing files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 287/287 [00:00<00:00, 1008.14it/s]\n",
      "Found 57174 files.\n",
      "2025-11-24 08:47:43,892 - __main__ - INFO - Saving eval samples\n"
     ]
    }
   ],
   "source": [
    "# ë°ì´í„°ì…‹ ìƒì„± (ì•½ 5-10ë¶„ ì†Œìš”)\n",
    "# ìœ„ ì…€ì—ì„œ ë°ì´í„°ì…‹ì´ ì—†ë‹¤ê³  í‘œì‹œëœ ê²½ìš°ì—ë§Œ ì‹¤í–‰í•˜ì„¸ìš”\n",
    "!python mouse_facial_expressions/data/make_datasets.py task1 --version \"1.1\" --frameset_size 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: í•™ìŠµ ì‹œì‘!\n",
    "\n",
    "### Option A: 1 epoch í…ŒìŠ¤íŠ¸ (~40-50ë¶„)\n",
    "\n",
    "ë¨¼ì € 1 epochë¡œ í…ŒìŠ¤íŠ¸í•˜ì—¬ ëª¨ë“  ê²ƒì´ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-24 08:47:46,927 - __main__ - INFO - beginning model run train_task1_baseline_model.py\n",
      "/opt/anaconda3/lib/python3.13/site-packages/mlflow/tracking/_tracking_service/utils.py:140: FutureWarning: Filesystem tracking backend (e.g., './mlruns') is deprecated. Please switch to a database backend (e.g., 'sqlite:///mlflow.db'). For feedback, see: https://github.com/mlflow/mlflow/issues/18534\n",
      "  return FileStore(store_uri, store_uri)\n",
      "2025/11/24 08:47:47 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Cmd('git') failed due to: exit code(1)\n",
      "  cmdline: git version\n",
      "  stderr: 'xcode-select: note: No developer tools were found, requesting install.\n",
      "If developer tools are located at a non-default location on disk, use `sudo xcode-select --switch path/to/Xcode.app` to specify the Xcode that you wish to use for command line developer tools, and cancel the installation dialog.\n",
      "See `man xcode-select` for more details.'\n",
      "2025-11-24 08:47:47,204 - __main__ - INFO - Started mlflow crossvalidation run 2d81e0461c21459ca39ad9af7f9e06f8\n",
      "2025-11-24 08:47:47,204 - __main__ - INFO - Logging parameters\n",
      "{\n",
      "    \"epochs\": 1,\n",
      "    \"dataset_version\": \"1.1\",\n",
      "    \"model\": 10,\n",
      "    \"learning_rate\": 0.01,\n",
      "    \"train_batch_size\": 20,\n",
      "    \"test_batch_size\": 50,\n",
      "    \"warmup_steps\": 0,\n",
      "    \"momentum\": 0.9,\n",
      "    \"weight_decay\": 0.0001,\n",
      "    \"warmup_decay\": 0.0001,\n",
      "    \"label_smoothing\": 0.1,\n",
      "    \"train_augmentation\": \"TrivialAugmentWide\",\n",
      "    \"seed\": 97531\n",
      "}\n",
      "2025-11-24 08:47:47,235 - __main__ - INFO - Starting training for fold 0 with seed 97531\n",
      "2025-11-24 08:47:47,235 - __main__ - INFO - Logging parameters\n",
      "{\n",
      "    \"epochs\": 1,\n",
      "    \"dataset_version\": \"1.1\",\n",
      "    \"model\": 10,\n",
      "    \"learning_rate\": 0.01,\n",
      "    \"train_batch_size\": 20,\n",
      "    \"test_batch_size\": 50,\n",
      "    \"warmup_steps\": 0,\n",
      "    \"momentum\": 0.9,\n",
      "    \"weight_decay\": 0.0001,\n",
      "    \"warmup_decay\": 0.0001,\n",
      "    \"label_smoothing\": 0.1,\n",
      "    \"train_augmentation\": \"TrivialAugmentWide\",\n",
      "    \"seed\": 97531\n",
      "}\n",
      "2025-11-24 08:47:47,241 - __main__ - INFO - Creating dataloader\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "/opt/anaconda3/lib/python3.13/site-packages/lightning/pytorch/trainer/setup.py:166: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "\n",
      "  | Name      | Type               | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | model_    | ResNet             | 21.3 M | train\n",
      "1 | fc        | Linear             | 4      | train\n",
      "2 | criterion | CrossEntropyLoss   | 0      | train\n",
      "3 | train_acc | MulticlassAccuracy | 0      | train\n",
      "4 | val_acc   | MulticlassAccuracy | 0      | train\n",
      "---------------------------------------------------------\n",
      "21.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "21.3 M    Total params\n",
      "85.141    Total estimated model params size (MB)\n",
      "120       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "Sanity Checking: |                                        | 0/? [00:00<?, ?it/s]/opt/anaconda3/lib/python3.13/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:428: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n",
      "2025-11-24 08:48:17,498 - __main__ - INFO - Validation 0, loss 0.449, accuracy 0.900\n",
      "/opt/anaconda3/lib/python3.13/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:428: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n",
      "Epoch 0:   1%|â–                                 | 3/500 [00:10<29:28,  0.28it/s]"
     ]
    }
   ],
   "source": [
    "# 1 epoch í…ŒìŠ¤íŠ¸\n",
    "!python mouse_facial_expressions/models/train_task1_baseline_model.py --epochs 1 --dataset_version \"1.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option B: ì „ì²´ í•™ìŠµ 10 epochs (~7-8ì‹œê°„)\n",
    "\n",
    "âš ï¸ ì´ ì…€ì€ ì˜¤ë˜ ê±¸ë¦½ë‹ˆë‹¤. ë°¤ìƒˆ ì‹¤í–‰í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 epochs ì „ì²´ í•™ìŠµ\n",
    "!python mouse_facial_expressions/models/train_task1_baseline_model.py --epochs 10 --dataset_version \"1.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: í•™ìŠµ ëª¨ë‹ˆí„°ë§\n",
    "\n",
    "í•™ìŠµì´ ì§„í–‰ë˜ëŠ” ë™ì•ˆ ë‹¤ë¥¸ ì…€ì—ì„œ ì§„í–‰ ìƒí™©ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì²´í¬í¬ì¸íŠ¸ í™•ì¸\n",
    "import os\n",
    "import glob\n",
    "\n",
    "checkpoint_dir = 'models/checkpoints'\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    checkpoints = glob.glob(f'{checkpoint_dir}/*.ckpt')\n",
    "    if checkpoints:\n",
    "        print(f\"âœ… ì €ì¥ëœ ì²´í¬í¬ì¸íŠ¸ ({len(checkpoints)}ê°œ):\")\n",
    "        !ls -lht models/checkpoints/\n",
    "    else:\n",
    "        print(\"ì•„ì§ ì²´í¬í¬ì¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "else:\n",
    "    print(\"ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬ê°€ ì•„ì§ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLflow ì‹¤í—˜ ê²°ê³¼ í™•ì¸\n",
    "import mlflow\n",
    "import os\n",
    "\n",
    "mlflow.set_tracking_uri(\"file://\" + os.path.join(os.getcwd(), \"mlruns\"))\n",
    "\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "experiments = client.search_experiments()\n",
    "\n",
    "if experiments:\n",
    "    print(\"MLflow ì‹¤í—˜:\")\n",
    "    for exp in experiments:\n",
    "        print(f\"\\nì‹¤í—˜ ID: {exp.experiment_id}\")\n",
    "        print(f\"ì´ë¦„: {exp.name}\")\n",
    "        \n",
    "        runs = client.search_runs(exp.experiment_id, max_results=5)\n",
    "        if runs:\n",
    "            print(f\"\\nìµœê·¼ ì‹¤í–‰ ({len(runs)}ê°œ):\")\n",
    "            for run in runs:\n",
    "                print(f\"  - Run ID: {run.info.run_id[:8]}...\")\n",
    "                print(f\"    ìƒíƒœ: {run.info.status}\")\n",
    "                if run.data.metrics:\n",
    "                    print(f\"    ë©”íŠ¸ë¦­: {dict(list(run.data.metrics.items())[:3])}\")\n",
    "else:\n",
    "    print(\"ì•„ì§ MLflow ì‹¤í—˜ì´ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: ê²°ê³¼ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì°¾ê¸°\n",
    "import glob\n",
    "import re\n",
    "import os\n",
    "\n",
    "checkpoints = glob.glob('models/checkpoints/*.ckpt')\n",
    "if checkpoints:\n",
    "    best_acc = 0\n",
    "    best_ckpt = None\n",
    "    \n",
    "    for ckpt in checkpoints:\n",
    "        match = re.search(r'val_acc=([0-9.]+)', ckpt)\n",
    "        if match:\n",
    "            acc = float(match.group(1))\n",
    "            if acc > best_acc:\n",
    "                best_acc = acc\n",
    "                best_ckpt = ckpt\n",
    "    \n",
    "    if best_ckpt:\n",
    "        print(f\"ğŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸:\")\n",
    "        print(f\"   íŒŒì¼: {os.path.basename(best_ckpt)}\")\n",
    "        print(f\"   Validation Accuracy: {best_acc:.2%}\")\n",
    "        \n",
    "        # íŒŒì¼ í¬ê¸° í™•ì¸\n",
    "        size_mb = os.path.getsize(best_ckpt) / (1024 * 1024)\n",
    "        print(f\"   í¬ê¸°: {size_mb:.1f} MB\")\n",
    "    else:\n",
    "        print(\"ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ëª…ì—ì„œ val_accë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        print(\"\\nì €ì¥ëœ ì²´í¬í¬ì¸íŠ¸:\")\n",
    "        for ckpt in checkpoints:\n",
    "            print(f\"  - {os.path.basename(ckpt)}\")\n",
    "else:\n",
    "    print(\"ì•„ì§ ì²´í¬í¬ì¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ìœ ìš©í•œ íŒ\n",
    "\n",
    "### í•™ìŠµ ì¤‘ë‹¨í•˜ê¸°\n",
    "- Jupyter ë©”ë‰´: Kernel â†’ Interrupt\n",
    "- ë˜ëŠ” ì…€ ì‹¤í–‰ ì¤‘ â–  ë²„íŠ¼ í´ë¦­\n",
    "\n",
    "### í•™ìŠµ ì¬ê°œí•˜ê¸°\n",
    "ì²´í¬í¬ì¸íŠ¸ì—ì„œ í•™ìŠµì„ ì¬ê°œí•˜ë ¤ë©´ (ì•„ì§ êµ¬í˜„ë˜ì§€ ì•ŠìŒ):\n",
    "```python\n",
    "# í–¥í›„ ì¶”ê°€ ì˜ˆì •\n",
    "```\n",
    "\n",
    "### MLflow UI ì‹¤í–‰\n",
    "í„°ë¯¸ë„ì—ì„œ:\n",
    "```bash\n",
    "cd /Users/minakang/Desktop/mouse-facial-expressions-2023-main\n",
    "mlflow ui\n",
    "```\n",
    "ê·¸ëŸ° ë‹¤ìŒ ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:5000 ì ‘ì†\n",
    "\n",
    "### ë¬¸ì œ í•´ê²°\n",
    "\n",
    "**ì—ëŸ¬: FileNotFoundError (í”„ë ˆì„ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ)**\n",
    "- Step 3ì—ì„œ .env íŒŒì¼ì˜ ê²½ë¡œê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸\n",
    "- `data/frames_backup` ë˜ëŠ” `data/local_frames` í´ë”ì— í”„ë ˆì„ì´ ìˆëŠ”ì§€ í™•ì¸\n",
    "\n",
    "**ì—ëŸ¬: ModelCheckpoint could not find val_acc**\n",
    "- âœ… ì´ ë¬¸ì œëŠ” ìˆ˜ì •ë˜ì—ˆìŠµë‹ˆë‹¤! í•™ìŠµ ì½”ë“œê°€ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "**í•™ìŠµì´ ë„ˆë¬´ ëŠë¦¼**\n",
    "- CPUë¡œ í•™ìŠµí•˜ê¸° ë•Œë¬¸ì— ì •ìƒì…ë‹ˆë‹¤\n",
    "- 1 epochë‹¹ ì•½ 40-50ë¶„ ì†Œìš”\n",
    "- ë°¤ìƒˆ ì‹¤í–‰í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
